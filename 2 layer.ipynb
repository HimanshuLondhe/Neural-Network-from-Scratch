{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mnist import MNIST\n",
    "\n",
    "mndata = MNIST('samples')\n",
    "\n",
    "x_train, y_train = mndata.load_training()\n",
    "\n",
    "x_test, y_test = mndata.load_testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(y_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "y_test = pd.get_dummies(y_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y_test and x_test are from the original test data and x_val,y_val below are the validation datasets of size 6000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class neuralnet_phases():\n",
    "    def __init__(self,x_train,y_train):\n",
    "        \n",
    "        hiddenlayernodes = 130\n",
    "        self.learning_rate = 5\n",
    "        self.epoch_no = 1   # Counter for number of epochs \n",
    "        attributes = 784    # Input features\n",
    "        labels = 10         # Lables for numberes 0-9\n",
    "        \n",
    "        \n",
    "        self.w1 = np.random.randn(attributes,hiddenlayernodes)\n",
    "        self.b1 = np.zeros((1,hiddenlayernodes))\n",
    "    \n",
    "        \n",
    "        self.w2 = np.random.randn(hiddenlayernodes,labels)\n",
    "        self.b2 = np.zeros((1,labels))\n",
    "        \n",
    "        \n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    def feedforward(self):\n",
    "        z1 = np.dot(self.x_train,self.w1) + self.b1\n",
    "        self.layer1 = 1/(1 + np.exp(-z1))          \n",
    "        #sigmoid given as (1/1+ e^-z)\n",
    "        \n",
    "        z2 = np.dot(self.layer1,self.w2) + self.b2\n",
    "        exps = np.exp(z2 - np.max(z2, axis=1, keepdims=True))\n",
    "        self.layer2 = exps/np.sum(exps, axis=1, keepdims=True)\n",
    "        # softmax given as (e^(z-max(z)/summation of z))\n",
    "        \n",
    "    def backpropogation(self):\n",
    "\n",
    "        logLik = - np.log(self.layer2[np.arange(self.y_train.shape[0]), self.y_train.argmax(axis=1)])\n",
    "        loss = np.sum(logLik)/self.y_train.shape[0]\n",
    "        \n",
    "        print(\"The Loss after epoch \",self.epoch_no,\" is: \",loss)\n",
    "        \n",
    "        self.epoch_no += 1\n",
    "        \n",
    "        #no derivative for z3 as explaied before.\n",
    "        layer2dt = ((self.layer2 - self.y_train)/(self.y_train.shape[0]))\n",
    "        \n",
    "        z1dt = np.dot(layer2dt,self.w2.T)\n",
    "        layer1dt = z1dt * (self.layer1 * (1 - self.layer1)) # sigmoid derivative given as (x * (1-x))\n",
    "        \n",
    "        \n",
    "        self.w2 -= self.learning_rate * np.dot(self.layer1.T,layer2dt)\n",
    "        self.b2 -= self.learning_rate * np.sum(layer2dt , axis = 0, keepdims = True)\n",
    "        \n",
    "        \n",
    "        self.w1 -= self.learning_rate * np.dot(self.x_train.T,layer1dt)\n",
    "        self.b1 -= self.learning_rate * np.sum(layer1dt, axis = 0 , keepdims = True)\n",
    "        \n",
    "    \n",
    "    def epochoutput(self,train):\n",
    "        self.x_train = train\n",
    "        self.feedforward()\n",
    "        return self.layer2.argmax()\n",
    "    \n",
    "fullyconnectedlayer = neuralnet_phases(x_train, y_train)\n",
    "\n",
    "for i in range(1000):\n",
    "    fullyconnectedlayer.feedforward()\n",
    "    fullyconnectedlayer.backpropogation()    \n",
    "    \n",
    "print(\"Done!\")\n",
    "\n",
    "def accuracy(train,test):\n",
    "    accuracy_counter = 0\n",
    "    for x,y in zip(train, test):\n",
    "        max_value_from_last_layer = fullyconnectedlayer.epochoutput(x)\n",
    "        if max_value_from_last_layer == np.argmax(y):\n",
    "            accuracy_counter +=1\n",
    "    return accuracy_counter/len(train)*100\n",
    "\n",
    "print(\"Training accuracy : \", accuracy(x_train, y_train))\n",
    "# print(\"Test accuracy : \", accuracy(x_val, y_val))\n",
    "print(\"Actual Test Accuracy: \",accuracy(x_test,y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
